{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate capacity headroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandapower as pp\n",
    "import pandapower.plotting as plot\n",
    "from datetime import date, datetime\n",
    "import yaml\n",
    "import folium\n",
    "import copy\n",
    "import json\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import os,sys,inspect\n",
    "\n",
    "#To import packages from parent subfolder \n",
    "currentdir =  os.path.abspath(os.getcwd())\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "from capacitymap.grid.grid import Grid, generate_config_from_project, combine_dict, daterange\n",
    "from capacitymap.analysis import analysis_check \n",
    "analysis_check.check_violations.counter = 0 #to make it run on first run\n",
    "from capacitymap.analysis import capacity_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Before requests can be assessed we need to start gathering the relevant grid model and calculate available capacity. \n",
    "\n",
    "### Load network and create grid object\n",
    "We start off by loading the grid model. This is a grid model representing the grid at normal operation. Depending on use case there is a possibility to also store time limited projects which results in re-configurations to the normal grid. This functions is available from the grid class but not used for this use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  Svedala\n",
      "Normal operation grid model:  This pandapower network includes the following parameter tables:\n",
      "   - bus (108 elements)\n",
      "   - load (73 elements)\n",
      "   - gen (38 elements)\n",
      "   - shunt (27 elements)\n",
      "   - ext_grid (1 element)\n",
      "   - line (75 elements)\n",
      "   - trafo (53 elements)\n",
      "   - controller (38 elements)\n",
      "   - bus_geodata (108 elements)\n",
      " and the following results tables:\n",
      "   - res_bus (108 elements)\n",
      "   - res_line (75 elements)\n",
      "   - res_trafo (53 elements)\n",
      "   - res_ext_grid (1 element)\n",
      "   - res_load (73 elements)\n",
      "   - res_shunt (27 elements)\n",
      "   - res_gen (38 elements)\n",
      "List of planned configuration:  {}\n",
      "Planned projects:  Empty DataFrame\n",
      "Columns: [Start, End, Object_type, ObjectID, Status]\n",
      "Index: []\n",
      "Active date:  None\n",
      "Active config:  None\n"
     ]
    }
   ],
   "source": [
    "# Pandapower grid\n",
    "net = pp.from_json(os.path.join(currentdir,'data\\svedala\\svedala.json')) \n",
    "\n",
    "# Dataframe over planned projects, to start this list is empty\n",
    "projects = pd.DataFrame(columns=['Start', 'End', 'Object_type','ObjectID', 'Status'])\n",
    "\n",
    "# Create grid object\n",
    "svedala = Grid('Svedala',net, {}, projects)\n",
    "\n",
    "#Print svedala information:\n",
    "print('Name: ', svedala.name)\n",
    "print('Normal operation grid model: ', svedala.grid)\n",
    "print('List of planned configuration: ', svedala.config_dict)\n",
    "print('Planned projects: ', svedala.project_df)\n",
    "print('Active date: ', svedala.active_date)\n",
    "print('Active config: ', svedala.active_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define limits and contingency test\n",
    "Before we can start with the capacity calculation we need to define the thresholds for the test we check for every power flow we run. The analysis builds on 8 test, if one of these fails the enterie scenario fails. The tests are:\n",
    "1. Upper limit on bus bus voltage\n",
    "2. Lower limit on bus voltage\n",
    "3. Max loading on line exceeded\n",
    "4. Max loading on trafo exceeded\n",
    "5. Subscription limit to overlying network exceeded\n",
    "6. Unsupplied loads\n",
    "7. Power flow did not converge, meaning something is really wrong :)\n",
    "\n",
    "Dependning on what test we run these thresholds can vary. For capacity calculation we run two types of calculations, one for normal operations and one for contingency scenarios (relevant N-1). We therfore define two sets of limits to validate available capacity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal operation limits\n",
    "normal_limits = {'vmin': 0.9,\n",
    "                'vmax': 1.12,\n",
    "                'max_line_loading' : 105,\n",
    "                'max_trafo_loading' : 100,\n",
    "                'subscription_p_limits': 1000,\n",
    "                'run_controllers': True}\n",
    "\n",
    "# Limits for continency tests\n",
    "cont_limits = {'vmin': 0.87,\n",
    "                'vmax': 1.15,\n",
    "                'max_line_loading' : 120,\n",
    "                'max_trafo_loading' : 120,\n",
    "                'subscription_p_limits': 1000,\n",
    "                'run_controllers': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the contingency test, we need to define which objects to test. The list consists of two lists, one over lines to test and one over trafos to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fileObject = open(os.path.join(currentdir,\"data\\\\svedala\\\\line_to_test.json\"), \"r\")\n",
    "jsonContent = fileObject.read()\n",
    "lines_to_test = json.loads(jsonContent)\n",
    "\n",
    "fileObject = open(os.path.join(currentdir,\"data\\\\svedala\\\\trafo_to_test.json\"), \"r\")\n",
    "jsonContent = fileObject.read()\n",
    "trafos_to_test = json.loads(jsonContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_scenario = [lines_to_test, trafos_to_test]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define capacity headroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define type of capacity (generation or load)\n",
    "cap_type = 'load'\n",
    "\n",
    "# Define max headroom to test\n",
    "upper_lim_p = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate capacity headroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                    ] 0% (number of PFs: 217)"
     ]
    }
   ],
   "source": [
    "cap_headroom = capacity_analysis.headroom(svedala.grid, cap_type,upper_lim_p, normal_limits=normal_limits, contingency_limits=cont_limits,contingency_scenario=contingency_scenario )\n",
    "#Save result to json\n",
    "#capfile = 'data\\\\svedala\\\\'+svedala.name+'_headroom_'+cap_type+'.json'\n",
    "#cap_headroom.to_json(os.path.join(currentdir,capfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                    ] 1% (number of PFs: 380)Max capacity is available\n",
      "[=                   ] 8% (number of PFs: 706)Max capacity is available\n",
      "[====                ] 20% (number of PFs: 1753)Max capacity is available\n",
      "[====                ] 21% (number of PFs: 1798)Max capacity is available\n",
      "[====                ] 22% (number of PFs: 1843)Max capacity is available\n",
      "[========            ] 44% (number of PFs: 3405)Max capacity is available\n",
      "[=========           ] 49% (number of PFs: 3790)Max capacity is available\n",
      "[==========          ] 52% (number of PFs: 4001)Max capacity is available\n",
      "[===========         ] 58% (number of PFs: 4710)Max capacity is available\n",
      "[=============       ] 68% (number of PFs: 5615)Max capacity is available\n",
      "[===============     ] 75% (number of PFs: 6757)Max capacity is available\n",
      "[===============     ] 79% (number of PFs: 7002)Max capacity is available\n",
      "[================    ] 82% (number of PFs: 7151)Max capacity is available\n",
      "[=================== ] 95% (number of PFs: 7703)Max capacity is available\n",
      "[====================] 100% (number of PFs: 8142)"
     ]
    }
   ],
   "source": [
    "# Define type of capacity (generation or load)\n",
    "cap_type = 'sgen'\n",
    "\n",
    "# Define max headroom to test\n",
    "upper_lim_p = 500\n",
    "cap_headroom = capacity_analysis.headroom(svedala.grid, cap_type,upper_lim_p, normal_limits=normal_limits, contingency_limits=cont_limits,contingency_scenario=contingency_scenario )\n",
    "\n",
    "#Save result to json\n",
    "#capfile = 'data\\\\svedala\\\\'+svedala.name+'_headroom_'+cap_type+'.json'\n",
    "#cap_headroom.to_json(os.path.join(currentdir,capfile))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99a6eba8d56053f83d876fbd4d8fcae42d7c67f6132c29b8a3e34802751afe5a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
